---
ensemble:
  vars:
    arg_dataset:    training
    arg_batch:      4
    arg_queue:      8
    arg_strategy:   default
    arg_epochs:     10
    arg_filter_factor:  0.25
    prep: |
      module load hpc/cuda/11.2
      . /hpcpackages/python/miniconda3/etc/profile.d/conda.sh
      conda activate $HOME/miniconda3/envs/icenet2
    symlinks:
      - ../../../train.py
      - ../../../loader.laptop.json
      - ../../../dataset_config.laptop.json
      - ../../../network_datasets
      - ../../../results
    gpus:         2
    mem:          128gb

  pre_process:
    - name:   execute
      args:
        cmd:  mkdir -p ../results/networks
  post_process: []

  batch_config:
    templatedir:  ../template
    templates:
    - icenet_train.sh.j2
    email:        jambyr@bas.ac.uk
    job_file:     icenet_run.sh
    cluster:      gpu
    nodes:        1
    ntasks:       4
    length:       02:00:00
    maxruns:      6
    maxjobs:      2

  batches:
    - name:       draft
      basedir:    ./ensemble/draft
      pre_batch:  []
      pre_run:    []
      runs:
        - seed:   42
        - seed:   43
        - seed:   44
        - seed:   45
        - seed:   46
      post_run:   []
      post_batch: []


